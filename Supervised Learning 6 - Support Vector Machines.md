# Supervise Learning 5 - Support Vector Machines

## Introduction

Given a linearly seperable data set there be potentially infinite ways of seperating data. How would you draw the best line of fit? You would want the line that provides the biggest buffer between any of your data. A line that gets closer to the data can be thought of trusting the data too much or overfitting. This example of overfitting is a bit different than what we've previously seen.

## Support Vector Machines

So going with a set of linearly seperable data set
 
y = mx + b <- 2 dimmensional version
y = w^Tx + b <- More general formula for hyperplanes and works for multiple dimensions of parameters

y is label {-1, +1} (note: not quite the same as the y in y = mx + b)
w^T and b are parameters of the plane

So we want to find the seperator that is the furtherst from the data sets but is still consistent.

## Optimal Seperator



## Linearly Married



## Kernal



## Summary



## Boosting and overfitting


